{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb44ace-5e5d-4969-bcf3-9a53cc33500c",
   "metadata": {},
   "source": [
    "# Lab 3: Logistic Regression\n",
    "\n",
    "### Dataset: \n",
    "Predicting the weather: https://www.kaggle.com/datasets/ananthr1/weather-prediction\n",
    "\n",
    "Or maybe driving style: https://www.kaggle.com/datasets/outofskills/driving-behavior\n",
    "\n",
    "Group: Benjamin Kuo & Nick Benso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e9bdda-1d93-48d1-960b-3acf32b613a9",
   "metadata": {},
   "source": [
    "## Preparation and Overview (3 points total)\n",
    "[2 points] Explain the task and what business-case or use-case it is designed to solve (or designed to investigate). Detail exactly what the classification task is and what parties would be interested in the results. For example, would the model be deployed or used mostly for offline analysis? As in previous labs, also detail how good the classifier needs to perform in order to be useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec83918-db1f-4e9b-b124-2ac7af863e7e",
   "metadata": {},
   "source": [
    "[.5 points] (mostly the same processes as from previous labs) Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis. Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). Provide a breakdown of the variables after preprocessing (such as the mean, std, etc. for all variables, including numeric and categorical).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9bb61d-2c9c-4c77-9c5f-85b7c3457187",
   "metadata": {},
   "source": [
    "[.5 points] Divide your data into training and testing data using an 80% training and 20% testing split. Use the cross validation modules that are part of scikit-learn. Argue \"for\" or \"against\" splitting your data using an 80/20 split. That is, why is the 80/20 split appropriate (or not) for your dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4987f863-286e-4e7a-ad34-28f237379eac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1461 entries, 0 to 1460\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           1461 non-null   object \n",
      " 1   precipitation  1461 non-null   float64\n",
      " 2   temp_max       1461 non-null   float64\n",
      " 3   temp_min       1461 non-null   float64\n",
      " 4   wind           1461 non-null   float64\n",
      " 5   weather        1461 non-null   object \n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 68.6+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1461 entries, 0 to 1460\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   precipitation  1461 non-null   float64\n",
      " 1   temp_max       1461 non-null   float64\n",
      " 2   temp_min       1461 non-null   float64\n",
      " 3   wind           1461 non-null   float64\n",
      " 4   weather        1461 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 57.2 KB\n"
     ]
    }
   ],
   "source": [
    "%config Completer.use_jedi = False\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "df = pd.read_csv('seattle-weather.csv') # read in the csv file\n",
    "print(df.info())\n",
    "\n",
    "# separate data types\n",
    "date_features = 'date'\n",
    "numerical_features = ['precipitation','temp_max','temp_min','wind']\n",
    "weather_features = ['weather']\n",
    "df['weather'].replace(['drizzle', 'fog', 'rain', 'snow', 'sun'],\n",
    "                        [0, 1, 2, 3, 4], inplace=True)\n",
    "\n",
    "# define with correct data types\n",
    "del df['date']\n",
    "df[numerical_features] = df[numerical_features].astype(np.float64)\n",
    "df[weather_features] = df[weather_features].astype(np.int64)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de03150c-21b8-43f3-9d4d-87becdb8c522",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=3, random_state=None, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'weather' in df:\n",
    "    y = df['weather'].to_numpy() # get the labels we want\n",
    "    del df['weather'] # get rid of the class label\n",
    "    \n",
    "    norm_features = ['precipitation', 'temp_max', 'temp_min', 'wind' ]\n",
    "    df[norm_features] = (df[norm_features]-df[norm_features].mean()) / df[norm_features].std()\n",
    "    X = df.to_numpy() # use everything else to predict!\n",
    "\n",
    "    ## X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    #    have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "#    of the object and set it up. This object will be able to split our data into \n",
    "#    training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(\n",
    "                         n_splits=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055cc4c7-7925-4c24-8ae2-789a7e3e1f74",
   "metadata": {},
   "source": [
    "## Modeling (5 points total)\n",
    "The implementation of logistic regression must be written only from the examples given to you by the instructor. No credit will be assigned to teams that copy implementations from another source, regardless of if the code is properly cited. \n",
    "\n",
    "[2 points] Create a custom, one-versus-all logistic regression classifier using numpy and scipy to optimize. Use object oriented conventions identical to scikit-learn. You should start with the template developed by the instructor in the course. You should add the following functionality to the logistic regression classifier:\n",
    "Ability to choose optimization technique when class is instantiated: either steepest ascent, stochastic gradient ascent, and {Newton's method/Quasi Newton methods}. \n",
    "Update the gradient calculation to include a customizable regularization term (either using no regularization, L1 regularization, L2 regularization, or both L1 and L2 regularization). Associate a cost with the regularization term, \"C\", that can be adjusted when the class is instantiated.  \n",
    "\n",
    "[1.5 points] Train your classifier to achieve good generalization performance. That is, adjust the optimization technique and the value of the regularization term(s) \"C\" to achieve the best performance on your test set. Visualize the performance of the classifier versus the parameters you investigated. Is your method of selecting parameters justified? \n",
    "\n",
    "[1.5 points] Compare the performance of your \"best\" logistic regression optimization procedure to the procedure used in scikit-learn. Visualize the performance differences in terms of training time and classification performance. Discuss the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7faf1398-5d54-4c98-b65d-20ef2f138ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BinaryLogisticRegressionBase:\n",
    "    # private:\n",
    "    def __init__(self, eta, C, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Base Binary Logistic Regression Object, Not Trainable'\n",
    "    \n",
    "    # convenience, private and static:\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return 1/(1+np.exp(-theta)) \n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_intercept(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self, X, add_intercept=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_intercept(X) if add_intercept else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BinaryLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, C=0.001):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "        \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    # convenience, private:\n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # vectorized gradient calculation with regularization using L2 Norm\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self,X,add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate \n",
    "            # add bacause maximizing  \n",
    "\n",
    "            \n",
    "class StochasticLogisticRegression(BinaryLogisticRegression):\n",
    "    # stochastic gradient calculation \n",
    "    def _get_gradient(self,X,y):\n",
    "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "        ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n",
    "        gradient = X[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "\n",
    "from scipy.optimize import fmin_bfgs # maybe the most common bfgs algorithm in the world\n",
    "from numpy import ma\n",
    "class BFGSBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    \n",
    "    @staticmethod\n",
    "    def objective_function(w,X,y,C):\n",
    "        g = expit(X @ w)\n",
    "        # invert this because scipy minimizes, but we derived all formulas for maximzing\n",
    "        return -np.sum(ma.log(g[y==1]))-np.sum(ma.log(1-g[y==0])) + C*sum(w**2) \n",
    "        #-np.sum(y*np.log(g)+(1-y)*np.log(1-g))\n",
    "\n",
    "    @staticmethod\n",
    "    def objective_gradient(w,X,y,C):\n",
    "        g = expit(X @ w)\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0)\n",
    "        gradient = gradient.reshape(w.shape)\n",
    "        gradient[1:] += -2 * w[1:] * C\n",
    "        return -gradient\n",
    "    \n",
    "    # just overwrite fit function\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = fmin_bfgs(self.objective_function, # what to optimize\n",
    "                            np.zeros((num_features,1)), # starting point\n",
    "                            fprime=self.objective_gradient, # gradient function\n",
    "                            args=(Xb,y,self.C), # extra args for gradient and objective function\n",
    "                            gtol=1e-03, # stopping criteria for gradient, |v_k|\n",
    "                            maxiter=self.iters, # stopping criteria iterations\n",
    "                            disp=False)\n",
    "        \n",
    "        self.w_ = self.w_.reshape((num_features,1))\n",
    "\n",
    "            \n",
    "from numpy.linalg import pinv\n",
    "class HessianBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # just overwrite gradient function\n",
    "    def _get_gradient(self,X,y):\n",
    "        g = self.predict_proba(X,add_bias=False).ravel() # get sigmoid value for all classes\n",
    "        hessian = X.T @ np.diag(g*(1-g)) @ X - 2 * self.C # calculate the hessian\n",
    "\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.sum(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return pinv(hessian) @ gradient\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# now lets do some vectorized coding\n",
    "from scipy.special import expit\n",
    "\n",
    "class VectorBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # inherit from our previous class to get same functionality\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # but overwrite the gradient calculation\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_intercept=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        return gradient.reshape(self.w_.shape)\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, eta, iterations=20):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = (y==yval) # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = VectorBinaryLogisticRegression(self.eta,\n",
    "                                                 self.iters)\n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return self.unique_[np.argmax(self.predict_proba(X),axis=1)] # take argmax along row\n",
    "    \n",
    "class MultiClassLogisticRegression:\n",
    "    def __init__(self, eta, iterations=20, \n",
    "                 C=0.0001, \n",
    "                 solver=BFGSBinaryLogisticRegression):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C = C\n",
    "        self.solver = solver\n",
    "        self.classifiers_ = []\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.sort(np.unique(y)) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = []\n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = np.array(y==yval).astype(int) # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            \n",
    "            hblr = self.solver(eta=self.eta,iterations=self.iters,C=self.C)\n",
    "            hblr.fit(X,y_binary)\n",
    "\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(hblr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for hblr in self.classifiers_:\n",
    "            probs.append(hblr.predict_proba(X).reshape((len(X),1))) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_proba(X),axis=1) # take argmax along row\n",
    "\n",
    "    \n",
    "class RegularizedBinaryLogisticRegression(VectorBinaryLogisticRegression):\n",
    "    # extend init functions\n",
    "    def __init__(self, C=0.0, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.C = C\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds) # call parent initializer\n",
    "        \n",
    "        \n",
    "    # extend previous class to change functionality\n",
    "    def _get_gradient(self,X,y):\n",
    "        # call get gradient from previous class\n",
    "        gradient = super()._get_gradient(X,y)\n",
    "        \n",
    "        # add in regularization (to all except bias term)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        return gradient\n",
    "\n",
    "\n",
    "class RegularizedLogisticRegression(LogisticRegression):\n",
    "    def __init__(self, C=0.0, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.C = C\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds) # call parent initializer\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = y==yval # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            # now this has regularization built into it\n",
    "            blr = RegularizedBinaryLogisticRegression(eta=self.eta,\n",
    "                                                      iterations=self.iters,\n",
    "                                                      C=self.C)\n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "784afaf6-6c86-4988-908c-163df7ad1fac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.7986348122866894\n",
      "confusion matrix\n",
      " [[  0   0   1   0   7]\n",
      " [  0   0   3   0  19]\n",
      " [  0   0 107   0  18]\n",
      " [  0   0   1   0   1]\n",
      " [  0   0   9   0 127]]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.764505119453925\n",
      "confusion matrix\n",
      " [[  0   0   2   0   5]\n",
      " [  0   0   2   0  21]\n",
      " [  0   0 124   0  26]\n",
      " [  0   0   5   0   1]\n",
      " [  0   0   7   0 100]]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.7679180887372014\n",
      "confusion matrix\n",
      " [[  0   0   0   0  15]\n",
      " [  0   0   4   0  15]\n",
      " [  0   0 110   0  19]\n",
      " [  0   0   2   0   0]\n",
      " [  0   0  13   0 115]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "lr_clf = MultiClassLogisticRegression(eta=0.1,iterations=10)\n",
    "iter_num = 0\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "    lr_clf.fit(X[train_indices],y[train_indices])  # train object\n",
    "    y_hat = lr_clf.predict(X[test_indices]) # get test set precitions\n",
    "\n",
    "    # print the accuracy and confusion matrix \n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", mt.accuracy_score(y[test_indices],y_hat)) \n",
    "    print(\"confusion matrix\\n\",mt.confusion_matrix(y[test_indices],y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4a88916-fb40-49c8-b4e1-4cdc020cefec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lr_explor(cost, theSolver):\n",
    "    lr_clf = MultiClassLogisticRegression(eta=0.1,iterations=10,\n",
    "                                            C=float(cost), solver = theSolver) # get object\n",
    "    acc = []\n",
    "    for iter_num, (train_indices, test_indices) in enumerate(cv_object.split(X,y)):\n",
    "        lr_clf.fit(X[train_indices],y[train_indices])  # train object\n",
    "        y_hat = lr_clf.predict(X[test_indices]) # get test set predictions\n",
    "        acc.append(mt.accuracy_score(y[test_indices],y_hat))\n",
    "        \n",
    "    acc = np.array(acc)\n",
    "    return acc\n",
    "\n",
    "costs = np.logspace(-5,1,20)\n",
    "steepestAscent = []\n",
    "for c in costs:\n",
    "    steepestAscent.append(lr_explor(c,BFGSBinaryLogisticRegression))\n",
    "\n",
    "stochasticGradientAscent = []\n",
    "for c in costs:\n",
    "    stochasticGradientAscent.append(lr_explor(c,StochasticLogisticRegression))\n",
    "\n",
    "newton = []\n",
    "for c in costs:\n",
    "    newton.append(lr_explor(c,HessianBinaryLogisticRegression))\n",
    "\n",
    "quasiNewton = []\n",
    "for c in costs:\n",
    "    quasiNewton.append(lr_explor(c,BFGSBinaryLogisticRegression))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "67835bd6-ccc5-48a6-a9e0-157dad276b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.boxplot(steepestAscent)\n",
    "plt.xticks(range(1,len(costs)+1),['%.4f'%(c) for c in costs],rotation='vertical')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.boxplot(stochasticGradientAscent)\n",
    "plt.xticks(range(1,len(costs)+1),['%.4f'%(c) for c in costs],rotation='vertical')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.boxplot(newton)\n",
    "plt.xticks(range(1,len(costs)+1),['%.4f'%(c) for c in costs],rotation='vertical')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.boxplot(quasiNewton)\n",
    "plt.xticks(range(1,len(costs)+1),['%.4f'%(c) for c in costs],rotation='vertical')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc9dec8-9152-463f-9884-49ad65e60b0e",
   "metadata": {},
   "source": [
    "## Deployment (1 points total)\n",
    "Which implementation of logistic regression would you advise be used in a deployed machine learning model, your implementation or scikit-learn (or other third party)? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7bbbcb-fae3-41b3-9ad5-3eafb3e54d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
